{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    fp = open(filename, encoding='utf8')#,'Ur')\n",
    "    data_list = []\n",
    "    sent=[]\n",
    "    x=0\n",
    "    for line in fp:\n",
    "        if (line.strip()=='.\\t.\\tO'):\n",
    "            sent.append(tuple(line.strip().split('\\t')))\n",
    "            data_list.append(sent)\n",
    "            sent=[]\n",
    "        else:\n",
    "            if(line.strip()==''):\n",
    "                x=1\n",
    "            else:\n",
    "                sent.append(tuple(line.strip().split('\\t')))\n",
    "    fp.close()\n",
    "    return data_list\n",
    "\n",
    "        #print (line)\n",
    "        #data_list.append(tuple(line.strip().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_sent_smpl=load_file(\"D:/D drive/DataAnalytics_StudyMaterial/IIMB-BDA/ProjectZ/Iteration2/Train1Sample.csv\")\n",
    "train_sent_smpl=load_file(\"D:/D drive/DataAnalytics_StudyMaterial/IIMB-BDA/ProjectZ/Iteration2/TrainData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_sent_sampl=load_file(\"D:/D drive/DataAnalytics_StudyMaterial/IIMB-BDA/ProjectZ/Iteration2/Test1Sample.csv\")\n",
    "test_sent_sampl=load_file(\"D:/D drive/DataAnalytics_StudyMaterial/IIMB-BDA/ProjectZ/Iteration2/TestData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.txt', 'test.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.corpus.conll2000.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#train_sents = list(nltk.corpus.conll2000.iob_sents('train.txt'))\n",
    "#test_sents = list(nltk.corpus.conll2000.iob_sents('test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hands', 'NNS', 'O'),\n",
       " ('on', 'IN', 'O'),\n",
       " ('experience', 'NN', 'WRKEX'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Java', 'NNP', 'SKILL'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('J2EE', 'NNP', 'SKILL'),\n",
       " ('(JDBC', 'NNP', 'SKILL'),\n",
       " ('Servlet', 'NNP', 'SKILL'),\n",
       " ('JSP).', 'NNP', 'SKILL'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sent_smpl[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2398"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sent_smpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sent_sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 632 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sent_smpl]\n",
    "y_train = [sent2labels(s) for s in train_sent_smpl]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sent_sampl]\n",
    "y_test = [sent2labels(s) for s in test_sent_sampl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 940 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 500,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Shashank Shekar'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#trainer.train('conll2002-esp.crfsuite')\n",
    "trainer.train('TotalCV2.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_features': 3738,\n",
       " 'error_norm': 73.534805,\n",
       " 'feature_norm': 71.145594,\n",
       " 'linesearch_step': 0.5,\n",
       " 'linesearch_trials': 2,\n",
       " 'loss': 10079.875607,\n",
       " 'num': 500,\n",
       " 'scores': {},\n",
       " 'time': 0.205}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logparser.last_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 {'num': 500, 'scores': {}, 'loss': 10079.875607, 'feature_norm': 71.145594, 'error_norm': 73.534805, 'active_features': 3738, 'linesearch_trials': 2, 'linesearch_step': 0.5, 'time': 0.205}\n"
     ]
    }
   ],
   "source": [
    "print (len(trainer.logparser.iterations), trainer.logparser.iterations[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0xf66dedebe0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('TotalCV2.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensive knowledge of CoreJava concepts like OOPS Concepts Multithreading Exception Handling Interfaces Abstract Class and Collection Framework. .\n",
      "\n",
      "Predicted: O O O O O O SKILL SKILL SKILL SKILL SKILL SKILL SKILL SKILL O SKILL SKILL O\n",
      "Correct:   O O O SKILL O O SKILL SKILL SKILL SKILL SKILL SKILL SKILL SKILL SKILL SKILL SKILL O\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_sent_sampl[2]\n",
    "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 82.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       DATE       0.96      0.77      0.85        91\n",
      "      DESIG       0.81      0.68      0.74        25\n",
      "        EDU       0.95      0.46      0.62        46\n",
      "      EMAIL       1.00      1.00      1.00         7\n",
      "        LOC       0.88      0.46      0.60        46\n",
      "        ORG       0.70      0.61      0.65       119\n",
      "       PERS       0.91      0.62      0.74        16\n",
      "      PHONE       0.75      0.60      0.67        10\n",
      "      SKILL       0.83      0.64      0.73       726\n",
      "      WRKEX       0.93      0.52      0.67        25\n",
      "\n",
      "avg / total       0.84      0.63      0.72      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "EMAIL  -> EMAIL   3.757939\n",
      "EDU    -> EDU     3.633941\n",
      "WRKEX  -> WRKEX   3.517239\n",
      "ORG    -> ORG     3.428494\n",
      "LOC    -> LOC     3.313029\n",
      "DESIG  -> DESIG   3.215806\n",
      "PHONE  -> PHONE   3.133305\n",
      "PERS   -> PERS    2.719366\n",
      "EMAIL  -> PHONE   2.564856\n",
      "ORG    -> LOC     2.270312\n",
      "DATE   -> DATE    2.222121\n",
      "SKILL  -> SKILL   1.862740\n",
      "PHONE  -> EMAIL   1.685653\n",
      "O      -> O       1.564512\n",
      "PERS   -> EMAIL   0.785996\n",
      "\n",
      "Top unlikely transitions:\n",
      "SKILL  -> LOC     -1.920234\n",
      "DATE   -> SKILL   -1.947272\n",
      "ORG    -> SKILL   -1.990016\n",
      "DESIG  -> SKILL   -2.007271\n",
      "SKILL  -> ORG     -2.038188\n",
      "PERS   -> ORG     -2.153862\n",
      "SKILL  -> DESIG   -2.230103\n",
      "PHONE  -> SKILL   -2.284765\n",
      "SKILL  -> PHONE   -2.444673\n",
      "SKILL  -> DATE    -2.457903\n",
      "WRKEX  -> SKILL   -2.528212\n",
      "SKILL  -> EDU     -2.983153\n",
      "SKILL  -> PERS    -3.030185\n",
      "EDU    -> SKILL   -3.181291\n",
      "PERS   -> SKILL   -3.211644\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "6.386089 O      word.lower=using\n",
      "6.031084 DATE   -1:word.lower=till\n",
      "4.836144 DATE   word.lower=may\n",
      "4.832337 SKILL  word.lower=hive\n",
      "4.650458 ORG    word.lower=telenet\n",
      "4.328767 LOC    word.lower=bangalore\n",
      "4.303009 SKILL  word.lower=jquery\n",
      "4.301115 SKILL  word.lower=angular\n",
      "4.290237 WRKEX  +1:word.lower=years\n",
      "4.170748 SKILL  word.lower=spark\n",
      "4.103823 SKILL  word.lower=wordpress\n",
      "4.092707 LOC    word.lower=hyderabad\n",
      "4.075117 ORG    word.lower=hospital\n",
      "4.069478 SKILL  word.lower=unix\n",
      "4.055064 O      EOS\n",
      "3.991890 LOC    word.lower=pune\n",
      "3.934869 ORG    -1:word.lower=client:\n",
      "3.856411 DESIG  -1:word.lower=team\n",
      "3.850966 WRKEX  +1:word.lower=year\n",
      "3.816833 SKILL  word[-2:]=JS\n",
      "\n",
      "Top negative:\n",
      "-1.406615 SKILL  -1:word.lower=java\n",
      "-1.407054 LOC    word[-2:]=on\n",
      "-1.426566 PHONE  BOS\n",
      "-1.441366 O      word.lower=dell\n",
      "-1.459049 O      word.lower=certificate\n",
      "-1.566300 SKILL  word.lower=experience\n",
      "-1.589936 O      word.lower=manual\n",
      "-1.642699 O      word[-3:]=pal\n",
      "-1.749610 O      word.lower=hospital\n",
      "-1.792006 o      bias\n",
      "-1.792480 O      +1:word.lower=india\n",
      "-1.836381 O      +1:word.lower=company:\n",
      "-1.903302 O      +1:word.lower=â€“\n",
      "-1.938250 O      word[-3:]=dle\n",
      "-1.943049 O      word.lower=oracle\n",
      "-1.974505 O      +1:word.lower=designer\n",
      "-1.983713 O      +1:word.lower=science\n",
      "-2.173715 O      word[-3:]=com\n",
      "-2.324225 O      -1:word.lower=â€“\n",
      "-2.362172 O      +1:word.lower=demand\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(20))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(info.state_features).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
